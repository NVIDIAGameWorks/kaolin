{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84d7733-cedb-4f90-a68e-63c016b6e633",
   "metadata": {},
   "source": [
    "# Physics Simulation and Interaction\n",
    "\n",
    "Have you recently generated or captured an awesome 3D object and want to interact with it without pre-processing it for physics simulation? With Kaolin implementation of Simplicits it is now very easy to run deformable physics simulation on any point sampled geometry.\n",
    "\n",
    "Let's go step-by-step on this simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c376c00-01a4-4055-b4d3-3dee0231b8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy, math, os, sys, logging, threading\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import kaolin as kal\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, stream=sys.stdout)\n",
    "sys.path.append(str(Path(\"..\")))\n",
    "from tutorial_common import COMMON_DATA_DIR\n",
    "\n",
    "def sample_mesh_path(fname):\n",
    "    return os.path.join(COMMON_DATA_DIR, 'meshes', fname)\n",
    "\n",
    "def print_tensor(t, name='', **kwargs):\n",
    "    print(kal.utils.testing.tensor_info(t, name=name, **kwargs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679490a-3664-47f0-af70-709cdecc7b2b",
   "metadata": {},
   "source": [
    "## Loading Geometry\n",
    "\n",
    "Simplicits physics method works with **any** point sampled geometry - point clouds, Gaussian splats, meshes.\n",
    "\n",
    "For the purpose of this tutorial, we will use a mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c13e6a0-8b51-4857-bf94-d6c39d659103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurfaceMesh object with batching strategy NONE\n",
      "            vertices: [9204, 3] (torch.float32)[cuda:0]  \n",
      "               faces: [18400, 3] (torch.int64)[cuda:0]  \n",
      "             normals: [8507, 3] (torch.float32)[cuda:0]  \n",
      "    face_normals_idx: [18400, 3] (torch.int64)[cuda:0]  \n",
      "                 uvs: [10800, 2] (torch.float32)[cuda:0]  \n",
      "        face_uvs_idx: [18400, 3] (torch.int64)[cuda:0]  \n",
      "material_assignments: [18400] (torch.int16)[cuda:0]  \n",
      "           materials: list of length 2\n",
      "       face_vertices: if possible, computed on access from: (faces, vertices)\n",
      "        face_normals: if possible, computed on access from: (normals, face_normals_idx) or (vertex_normals, faces) or (vertices, faces)\n",
      "            face_uvs: if possible, computed on access from: (uvs, face_uvs_idx)\n",
      "      vertex_normals: if possible, computed on access from: (faces, face_normals)\n",
      "     vertex_tangents: if possible, computed on access from: (faces, face_vertices, face_uvs, vertex_normals)\n",
      "       vertex_colors: if possible, computed on access from: (faces, face_colors)\n",
      "     vertex_features: if possible, computed on access from: (faces, face_features)\n",
      "       face_tangents: if possible, computed on access from: (faces, vertex_tangents)\n",
      "         face_colors: if possible, computed on access from: (faces, vertex_colors)\n",
      "       face_features: if possible, computed on access from: (faces, vertex_features)\n"
     ]
    }
   ],
   "source": [
    "# Import and triangulate to enable rasterization; move to GPU\n",
    "mesh = kal.io.import_mesh(sample_mesh_path('armchair.obj'), triangulate=True).cuda()\n",
    "    \n",
    "# Normalize so it is easy to set up default camera\n",
    "mesh.vertices = kal.ops.pointcloud.center_points(mesh.vertices.unsqueeze(0), normalize=True).squeeze(0) \n",
    "orig_vertices = mesh.vertices.clone()  # Also save original undeformed vertices\n",
    "\n",
    "# Inspect\n",
    "print(mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d9dcb-e0b0-4a71-bd20-a4ed3a72c303",
   "metadata": {},
   "source": [
    "## Visualizing Geometry\n",
    "\n",
    "Because we are working with a mesh, Kaolin already comes with an easy render function. To use any rendering function (such as a Gaussan splat renderer),\n",
    "simply define the following rendering functions that take `Camera` as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174d9a37-e6c3-4ac1-9f1d-38104595d824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f87088de0b24e7192e317a48bfc993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=512, width=512),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd892c81c1ee4f329be9f6a34baa5f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def render(in_cam, **kwargs):\n",
    "    # render_res = kal.render.easy_render.render_mesh(in_cam, mesh, **kwargs)\n",
    "    # img = render_res[kal.render.easy_render.RenderPass.render].squeeze(0).clamp(0, 1)\n",
    "    # return {\"img\": (img * 255.).to(torch.uint8),\n",
    "    #         \"face_idx\": render_res[kal.render.easy_render.RenderPass.face_idx].squeeze(0).unsqueeze(-1)}\n",
    "\n",
    "    active_pass=kal.render.easy_render.RenderPass.render\n",
    "    render_res = kal.render.easy_render.render_mesh(in_cam, mesh, **kwargs)\n",
    "    \n",
    "    img = render_res[active_pass]\n",
    "    background_mask = (render_res[kal.render.easy_render.RenderPass.face_idx] < 0).bool()\n",
    "    img2 = torch.clamp(img, 0, 1)[0]\n",
    "    img2[background_mask[0]] = 1\n",
    "    final = (img2 * 255.).to(torch.uint8)\n",
    "    return {\"img\":final, \"face_idx\": render_res[kal.render.easy_render.RenderPass.face_idx].squeeze(0).unsqueeze(-1)}\n",
    "\n",
    "def fast_render(in_cam, factor=8):\n",
    "    lowres_cam = copy.deepcopy(in_cam)\n",
    "    lowres_cam.width = in_cam.width // factor\n",
    "    lowres_cam.height = in_cam.height // factor\n",
    "    return render(lowres_cam)\n",
    "\n",
    "resolution = 512\n",
    "camera = kal.render.easy_render.default_camera(resolution).cuda()\n",
    "visualizer = kal.visualize.IpyTurntableVisualizer(\n",
    "    resolution, resolution, copy.deepcopy(camera), render, fast_render=fast_render,\n",
    "    max_fps=24, world_up_axis=1)\n",
    "display(HBox([visualizer.canvas]), visualizer.out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f36a68-f7d0-4039-9e79-4017f7c4ec05",
   "metadata": {},
   "source": [
    "## Preparing Geometry for Simulation\n",
    "\n",
    "To enable simulation of any point-sampled geometry, we first need to train Simplicits objects, given their physics material parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186a637d-f310-4ae1-af07-d4ad8cd67623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Physics material parameters\n",
    "soft_youngs_modulus = 1e5\n",
    "hard_youngs_modulus = 1e7\n",
    "poisson_ratio = 0.45\n",
    "rho = 100  # kg/m^3\n",
    "approx_volume = 1  # m^3\n",
    "\n",
    "# Point samples\n",
    "pts = mesh.vertices\n",
    "yms = torch.full((pts.shape[0],), soft_youngs_modulus, device=\"cuda\")\n",
    "prs = torch.full((pts.shape[0],), poisson_ratio, device=\"cuda\")\n",
    "rhos = torch.full((pts.shape[0],), rho, device=\"cuda\")\n",
    "\n",
    "# Initialize and train a Simpicits object to enable simulation\n",
    "sim_obj = kal.physics.simplicits.SimplicitsObject(pts, yms, prs, rhos, torch.tensor([approx_volume], dtype=torch.float32, device=\"cuda\"), num_handles=10)\n",
    "sim_obj.train(num_steps=10000, le_coeff=0.1)#0) # do nothing if num_handles = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1caf6f-3355-4fc4-a5d1-8d44a6b338e0",
   "metadata": {},
   "source": [
    "# Saving/Loading Network\n",
    "It could be useful to save the network/load the network from disk for an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba8bf65-0464-4ea9-be7a-a14a1fcfdfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(sim_obj.model, \"./results/sim_obj_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49182020-c2aa-4029-a736-8ae632f6c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model = torch.load(\"./results/sim_obj_model\").to(device=\"cuda\")\n",
    "#sim_obj.model = loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb600492-0163-4b6f-8e16-261dd1422e57",
   "metadata": {},
   "source": [
    "## Setting up Simulation\n",
    "\n",
    "Once the object is trained, we can set up any number of simulated scenes with that object. \n",
    "\n",
    "Let's set up a default scene that includes floor and can cause falling under gravity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdbc2133-e555-40cd-996d-32b7688ae6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scene with default simulation parameters\n",
    "scene1 = kal.physics.simplicits.SimplicitsScene() \n",
    "# Reduce to 3 newton steps per timestep for speed\n",
    "scene1.max_newton_steps = 3\n",
    "\n",
    "# Add an object to the scene\n",
    "obj_idx = scene1.add_object(sim_obj)\n",
    "obj_idx = 0  # Hack, fix return\n",
    "\n",
    "# Add gravity to the scene\n",
    "scene1.set_scene_gravity(acc_gravity=torch.tensor([0, 9.8, 0]))\n",
    "# Add floor to the scene\n",
    "scene1.set_scene_floor(floor_height=-1, floor_axis=1, floor_penalty=10000)\n",
    "# Make object even softer\n",
    "scene1.sim_obj_dict[obj_idx].set_materials(yms=torch.tensor(1e5, device=\"cuda\", dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eaf462-89ab-46bd-9d1a-87560788ccdd",
   "metadata": {},
   "source": [
    "## Running and Visualizing Simulation\n",
    "\n",
    "We will run the simulation, changing object point locations (mesh vertices in this case) at every timestep and will visualize at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57213485-260b-425e-9618-76a9e511424e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b410286cc7a3493caa3f242253b65685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=512, width=512), Button(description='Run Sim', style=ButtonStyle())))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36619e8f3e347eba2aa3957dce3fe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh.vertices = orig_vertices\n",
    "\n",
    "resolution = 512\n",
    "new_camera = kal.render.easy_render.default_camera(resolution).cuda()\n",
    "new_camera.extrinsics.move_forward(1)\n",
    "visualizer = kal.visualize.IpyTurntableVisualizer(\n",
    "    resolution, resolution, copy.deepcopy(new_camera), render, fast_render=fast_render,\n",
    "    max_fps=24, world_up_axis=1)\n",
    "\n",
    "def run_sim():\n",
    "    global sim_history\n",
    "    global mesh\n",
    "    \n",
    "    scene1.sim_obj_dict[obj_idx].reset_sim_state()\n",
    "    for s in range(150):\n",
    "        scene1.run_sim_step()\n",
    "        mesh.vertices = scene1.get_object_deformed_pts(obj_idx).squeeze()\n",
    "        visualizer.render_update()\n",
    "\n",
    "\n",
    "def start_simulation(b):\n",
    "    run_sim()\n",
    "        \n",
    "button = Button(description='Run Sim')\n",
    "button.on_click(start_simulation)\n",
    "display(HBox([visualizer.canvas, button]), visualizer.out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463113eb-401c-418e-b070-e4620f1551f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting up Interactive Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b49036cc-f2cb-40ed-adab-e4cf196aab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_offset_to_world_coords(kal_cam, point: torch.Tensor, offset: torch.Tensor):\n",
    "    \"\"\" Given a point in 3D and a 2D offset in NDC coordinates, maps the offset to \"world coordinate\" units.\n",
    "    In other words: recomputes the world coordinates had it been translated from point an \"offset\" amount in NDC\n",
    "    space (-1 to 1).\n",
    "    ps_camera: The current camera used to transform coords from world space -> camera view space -> NDC space\n",
    "    point: The 3D point we translate from\n",
    "    offset: A 2D offset in NDC coordinates\n",
    "    \"\"\"\n",
    "    if point.ndim == 1:\n",
    "        point = point[None]\n",
    "    # Ask kaolin about the camera up and right axes in world coordinates, and move along them an \"offset\" amount.\n",
    "    # offset is given in \"post projected\" NDC coordinates, so the amount isn't exactly camera-space units.\n",
    "    # However, the important part is we don't move along the camera-forward axis.\n",
    "    fov_x = kal_cam.fov_x\n",
    "    fov_y = kal_cam.fov_y\n",
    "    depth = torch.linalg.norm(point - kal_cam.cam_pos())\n",
    "    offset[0] = offset[0]/1000#*torch.tan(fov_x)\n",
    "    offset[1] = offset[1]/1000#*torch.tan(fov_y)\n",
    "    \n",
    "    translated_point = point.clone()\n",
    "    translated_point += kal_cam.cam_right().squeeze(-1) * offset[0]\n",
    "    translated_point += kal_cam.cam_up().squeeze(-1) * offset[1]\n",
    "    return translated_point\n",
    "    \n",
    "def find_closest_3d_points(query_3d_pts, object_3d_pts, radius, k=10):\n",
    "    \"\"\" Finds points from object_3d_pts to query_3d_pts\n",
    "        Pts should be within radius and limited to a number k\n",
    "    \"\"\"\n",
    "    # Define the radius\n",
    "    r = radius\n",
    "    # Calculate pairwise distances\n",
    "    dists = torch.cdist(query_3d_pts, object_3d_pts)\n",
    "    # Find points within radius r\n",
    "    within_radius = dists <= r\n",
    "    \n",
    "    # Get the indices of object_pts within radius r of any query_pts\n",
    "    indices_within_radius = torch.nonzero(within_radius, as_tuple=True)[1]\n",
    "    if k >= indices_within_radius.shape[0]:\n",
    "        return indices_within_radius, object_3d_pts[indices_within_radius]\n",
    "    else:\n",
    "        # Flatten distances tensor for sorting\n",
    "        dists_flat = dists[within_radius]\n",
    "        # Sort the distances and select top k\n",
    "        sorted_indices = torch.argsort(dists_flat)[:k]\n",
    "        # Select the top k indices\n",
    "        top_k_indices = indices_within_radius[sorted_indices]\n",
    "        # Get the points that are within the radius and in the top k closest\n",
    "        points_within_radius_top_k = object_3d_pts[top_k_indices]\n",
    "        # Get the points that are within the radius\n",
    "        return top_k_indices, points_within_radius_top_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083bce8-a220-42ca-952d-402a3088de94",
   "metadata": {},
   "source": [
    "### SHIFT and Click\n",
    "Now, let's enable pulling on object parts during simulation.\n",
    "To interact, simply press \"SHIFT\" and click on the mesh and drag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecdc3658-f66e-487a-893d-4b1d716f3de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d079c6c432ae43dd93777cbe4976678b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=512, width=512), Button(description='Run Test', style=ButtonStyle())))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95b14a6b7bc413d94aea86a58a0f037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "active_face = -1\n",
    "sim_history = []\n",
    "mesh.vertices = orig_vertices\n",
    "mouse_clicked = 0\n",
    "sim_history = []\n",
    "scene1.sim_obj_dict[obj_idx].reset_sim_state()\n",
    "\n",
    "def boundary_func(pts):\n",
    "    # Extract the z-coordinates (height) of the points\n",
    "    heights = pts[:, 1]\n",
    "    # Determine the minimum and maximum z-coordinates\n",
    "    z_min = torch.min(heights)\n",
    "    z_max = torch.max(heights)\n",
    "    # Calculate the threshold z-coordinate for the upper 10% of the object's height\n",
    "    threshold = z_min + 0.9 * (z_max - z_min)\n",
    "    # Get the indices of the points in the upper 10%\n",
    "    return heights >= threshold\n",
    "\n",
    "boundary1 = scene1.sim_obj_dict[obj_idx].set_boundary_condition(\"boundary1\", boundary_func, bdry_penalty=10000)\n",
    "\n",
    "def additional_event_handler(visualizer, event):\n",
    "    \"\"\"Event handler to be provided to Kaolin's visualizer\"\"\"\n",
    "    global active_face, mesh, mouse_clicked, pull_from_2d, sim_history\n",
    "    \n",
    "    with visualizer.out:\n",
    "        if event['shiftKey']:\n",
    "            #return simplicits_viz_logic(event, visualizer, mouse_clicked, boundary1, pull_from_2d, mesh)\n",
    "            if event['type'] == 'mousedown':\n",
    "                mouse_clicked = 1\n",
    "                pull_from_2d = torch.tensor(visualizer._get_clamped_coords(event), device='cuda', dtype=torch.float)\n",
    "                current_values = visualizer.get_values_under_cursor(event)\n",
    "                active_face = current_values['face_idx'][0][0]\n",
    "                if active_face == -1:\n",
    "                    boundary1.set_pinned_verts(None, None)\n",
    "                    return False\n",
    "        \n",
    "                bdry_inds, bdry_pts = find_closest_3d_points(mesh.vertices[mesh.faces[active_face],:], scene1.get_object_deformed_pts(obj_idx, scene1.sim_obj_dict[obj_idx].sim_pts).squeeze(), radius=0.2, k=10)\n",
    "                \n",
    "                boundary1.set_pinned_verts(bdry_inds, bdry_pts)\n",
    "                visualizer.render_update()\n",
    "                \n",
    "            if event['type'] == 'mousemove':\n",
    "                if mouse_clicked == 1:\n",
    "                    visualizer.out.clear_output()\n",
    "                    pull_to_2d = torch.tensor(visualizer._get_clamped_coords(event), device='cuda', dtype=torch.float)\n",
    "                    pull_to_2d = torch.tensor(visualizer._get_clamped_coords(event), device='cuda', dtype=torch.float)\n",
    "\n",
    "                    # Delta for clicked point\n",
    "                    pxl_offset = (pull_to_2d - pull_from_2d)\n",
    "\n",
    "                    # pxl_offset[0] /= visualizer.width \n",
    "                    # pxl_offset[1] /= visualizer.height\n",
    "\n",
    "                    pinned_verts = boundary1.pinned_vertices\n",
    "                    point = pinned_verts.mean(dim=0) # in 3D world coord\n",
    "                    # Convert to opengl sign convention\n",
    "                    pxl_offset[1] *= -1\n",
    "                    \n",
    "                    # Get updated location of bdry - TODO: (Or Perel) Need to fix this code\n",
    "                    updated_point = convert_offset_to_world_coords(visualizer.camera, point, pxl_offset)\n",
    "                    offset_3d = updated_point - point\n",
    "                    pinned_verts += offset_3d\n",
    "                    boundary1.update_pinned(pinned_verts)\n",
    "                    print(f'point:{point}')\n",
    "                    print(f'updated_pt:{updated_point}')\n",
    "                    print(f'offset:{offset_3d}')\n",
    "                \n",
    "            if event['type'] == 'mouseup':\n",
    "                if mouse_clicked == 1:\n",
    "                    mouse_clicked = 0\n",
    "                    \n",
    "            return False\n",
    "        return True\n",
    "\n",
    "new_camera = kal.render.easy_render.default_camera(resolution).cuda()\n",
    "new_camera.extrinsics.move_forward(1)\n",
    "visualizer = kal.visualize.IpyTurntableVisualizer(\n",
    "    resolution, resolution, copy.deepcopy(new_camera), render, fast_render=fast_render,\n",
    "    max_fps=24, world_up_axis=1,\n",
    "    additional_event_handler=additional_event_handler,\n",
    "    additional_watched_events=['mousedown', 'mousemove', 'keydown'] # We need to now watch for key press event\n",
    ")\n",
    "\n",
    "def run_sim():\n",
    "    # if shift is pressed, run our logic, else run default logic\n",
    "    for step in range(500):\n",
    "        with visualizer.out:\n",
    "            scene1.run_sim_step()\n",
    "            sim_history.append(scene1.get_object_deformed_pts(obj_idx).squeeze())\n",
    "            print('.', end='')\n",
    "        mesh.vertices = sim_history[-1]\n",
    "        visualizer.render_update()    \n",
    "\n",
    "# Run sim for num_steps in a different thread\n",
    "# Needed for interactivity\n",
    "def callback(b):\n",
    "    t = threading.Thread(target=run_sim, daemon=True)\n",
    "    t.start()\n",
    "        \n",
    "button = Button(description='Run Test')\n",
    "button.on_click(callback)\n",
    "display(HBox([visualizer.canvas, button]), visualizer.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ec2db-afd9-4642-a7eb-816e154997f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
