{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84d7733-cedb-4f90-a68e-63c016b6e633",
   "metadata": {},
   "source": [
    "# Physics Simulation and Interaction\n",
    "\n",
    "Have you recently generated or captured an awesome 3D object and want to interact with it without pre-processing it for physics simulation? With Kaolin implementation of [Simplicits](https://research.nvidia.com/labs/toronto-ai/simplicits/) it is now very easy to run deformable physics simulation on any point sampled geometry.\n",
    "\n",
    "Let's go step-by-step on this simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c376c00-01a4-4055-b4d3-3dee0231b8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy, math, os, sys, logging, threading\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import kaolin as kal\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "logging.getLogger('kaolin.physics').setLevel(logging.DEBUG)\n",
    "\n",
    "sys.path.append(str(Path(\"..\")))\n",
    "from tutorial_common import COMMON_DATA_DIR\n",
    "\n",
    "def sample_mesh_path(fname):\n",
    "    return os.path.join(COMMON_DATA_DIR, 'meshes', fname)\n",
    "\n",
    "def print_tensor(t, name='', **kwargs):\n",
    "    print(kal.utils.testing.tensor_info(t, name=name, **kwargs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679490a-3664-47f0-af70-709cdecc7b2b",
   "metadata": {},
   "source": [
    "## Loading Geometry\n",
    "\n",
    "Simplicits physics simulation method works with **any** point sampled geometry, such as point clouds, 3D Gaussian splats, and meshes.\n",
    "\n",
    "For the purpose of this tutorial, we will use a mesh of a chair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13e6a0-8b51-4857-bf94-d6c39d659103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and triangulate to enable rasterization; move to GPU\n",
    "mesh = kal.io.import_mesh(sample_mesh_path('armchair.obj'), triangulate=True).cuda()\n",
    "# Normalize so it is easy to set up default camera\n",
    "mesh.vertices = kal.ops.pointcloud.center_points(mesh.vertices.unsqueeze(0), normalize=True).squeeze(0) \n",
    "orig_vertices = mesh.vertices.clone()  # Also save original undeformed vertices\n",
    "print(mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d9dcb-e0b0-4a71-bd20-a4ed3a72c303",
   "metadata": {},
   "source": [
    "## Visualizing Geometry\n",
    "\n",
    "Because we are working with a mesh, Kaolin already comes with an easy render function. To use any rendering function (such as a Gaussan splat renderer),\n",
    "simply define the following rendering functions that take `Camera` as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d9a37-e6c3-4ac1-9f1d-38104595d824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def render(in_cam):\n",
    "    active_pass=kal.render.easy_render.RenderPass.render\n",
    "    render_res = kal.render.easy_render.render_mesh(in_cam, mesh)\n",
    "\n",
    "    # use white background\n",
    "    img = render_res[active_pass]\n",
    "    background_mask = (render_res[kal.render.easy_render.RenderPass.face_idx] < 0).bool()\n",
    "    img2 = torch.clamp(img, 0, 1)[0]\n",
    "    img2[background_mask[0]] = 1\n",
    "    final = (img2 * 255.).to(torch.uint8)\n",
    "    return {\"img\":final, \"face_idx\": render_res[kal.render.easy_render.RenderPass.face_idx].squeeze(0).unsqueeze(-1)}\n",
    "\n",
    "# faster low-res render during mouse motion\n",
    "def fast_render(in_cam, factor=8):\n",
    "    lowres_cam = copy.deepcopy(in_cam)\n",
    "    lowres_cam.width = in_cam.width // factor\n",
    "    lowres_cam.height = in_cam.height // factor\n",
    "    return render(lowres_cam)\n",
    "\n",
    "resolution = 512\n",
    "camera = kal.render.easy_render.default_camera(resolution).cuda()\n",
    "rest_state_viz = kal.visualize.IpyTurntableVisualizer(\n",
    "    resolution, resolution, copy.deepcopy(camera), render, fast_render=fast_render,\n",
    "    max_fps=24, world_up_axis=1)\n",
    "rest_state_viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f36a68-f7d0-4039-9e79-4017f7c4ec05",
   "metadata": {},
   "source": [
    "## Sample Geometry\n",
    "\n",
    "To enable simulation we need point samples (vertices in this case), and physical material parameters per point. Let's set this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a637d-f310-4ae1-af07-d4ad8cd67623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Physics material parameters\n",
    "soft_youngs_modulus = 1e5\n",
    "hard_youngs_modulus = 1e7\n",
    "poisson_ratio = 0.45\n",
    "rho = 100  # kg/m^3\n",
    "approx_volume = 1  # m^3\n",
    "\n",
    "# Point samples\n",
    "pts = mesh.vertices\n",
    "yms = torch.full((pts.shape[0],), soft_youngs_modulus, device=\"cuda\")\n",
    "prs = torch.full((pts.shape[0],), poisson_ratio, device=\"cuda\")\n",
    "rhos = torch.full((pts.shape[0],), rho, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb2e5a-0858-402e-b791-05a0dca99719",
   "metadata": {},
   "source": [
    "## Create and Train a SimplicitsObject\n",
    "We encapsulate everything Simplicits method needs to know about the simulated object in a `SimplicitsObject` instance. Once the object is created, we need to run training to learn reduced degrees of freedom our simulator can use. \n",
    "\n",
    "**This will take a couple of minutes.** Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f0ba6-9276-4ee5-a55b-223b08321178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train a Simpicits object to enable simulation\n",
    "sim_obj = kal.physics.simplicits.SimplicitsObject(pts, yms, prs, rhos, torch.tensor([approx_volume], dtype=torch.float32, device=\"cuda\"), num_handles=10)\n",
    "print('Training simplicits object. This will take 2-3min. ')\n",
    "sim_obj.train(num_steps=10000, le_coeff=0.1)#0) # do nothing if num_handles = 0\n",
    "print('Object ready to simulate.')\n",
    "\n",
    "# sim_obj.load_model('/tmp/chair_simplicit.pt') # if you saved previously trained object, you can load it instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2400b-193a-470c-a52a-5db1321ad9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can save/load this pre-trained object\n",
    "# sim_obj.save_model('/tmp/chair_simplicit.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb600492-0163-4b6f-8e16-261dd1422e57",
   "metadata": {},
   "source": [
    "## Setting up Simulation\n",
    "\n",
    "Once the object is trained, we can set up any number of simulated scenes with that object. \n",
    "\n",
    "Let's set up a default scene that includes floor and can cause falling under gravity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc2133-e555-40cd-996d-32b7688ae6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene1 = kal.physics.simplicits.SimplicitsScene() # default scene\n",
    "scene1.max_newton_steps = 3 # Smaller NM iteration count results in faster sims, but poorer convergence\n",
    "\n",
    "# Add an object to the scene\n",
    "obj_idx = scene1.add_object(sim_obj)\n",
    "\n",
    "# Add gravity to the scene\n",
    "scene1.set_scene_gravity(acc_gravity=torch.tensor([0, 9.8, 0]))\n",
    "# Add floor to the scene\n",
    "scene1.set_scene_floor(floor_height=-1, floor_axis=1, floor_penalty=10000)\n",
    "# Make object even softer\n",
    "scene1.sim_obj_dict[obj_idx].set_materials(yms=torch.tensor(1e5, device=\"cuda\", dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eaf462-89ab-46bd-9d1a-87560788ccdd",
   "metadata": {},
   "source": [
    "## Running and Visualizing Simulation\n",
    "\n",
    "We will run the simulation, changing object point locations (mesh vertices in this case) at every timestep and will visualize at the same time.\n",
    "\n",
    "Try changing camera position with your mouse and running the simulation to view it from another angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57213485-260b-425e-9618-76a9e511424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.vertices = orig_vertices\n",
    "\n",
    "new_camera = kal.render.easy_render.default_camera(resolution).cuda()\n",
    "new_camera.extrinsics.move_forward(1)\n",
    "standard_viz = kal.visualize.IpyTurntableVisualizer(\n",
    "    resolution, resolution, copy.deepcopy(new_camera), render, fast_render=fast_render,\n",
    "    max_fps=24, world_up_axis=1)\n",
    "standard_viz.render_update()\n",
    "\n",
    "def run_sim():\n",
    "    global mesh\n",
    "    \n",
    "    scene1.reset()\n",
    "    for s in range(60):\n",
    "        scene1.run_sim_step()\n",
    "        print(\".\", end=\"\")\n",
    "        mesh.vertices = scene1.get_object_deformed_pts(obj_idx).squeeze()\n",
    "        standard_viz.render_update()\n",
    "\n",
    "def start_simulation(b):\n",
    "    global button\n",
    "    button.disabled = True\n",
    "    with standard_viz.out:\n",
    "        run_sim()\n",
    "    button.disabled = False\n",
    "        \n",
    "button = Button(description='Run Sim')\n",
    "button.on_click(start_simulation)\n",
    "display(HBox([standard_viz.canvas, button]), standard_viz.out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463113eb-401c-418e-b070-e4620f1551f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting up Interactive Simulation\n",
    "\n",
    "In order to interact with the simulation in the view port, we need to connect cursor position to boundary conditions on the simulated object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49036cc-f2cb-40ed-adab-e4cf196aab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_offset_to_world_coords(kal_cam, point: torch.Tensor, offset: torch.Tensor):\n",
    "    \"\"\" Given a point in 3D and a 2D offset in NDC coordinates, maps the offset to \"world coordinate\" units.\n",
    "    In other words: recomputes the world coordinates had it been translated from point an \"offset\" amount in NDC\n",
    "    space (-1 to 1).\n",
    "    ps_camera: The current camera used to transform coords from world space -> camera view space -> NDC space\n",
    "    point: The 3D point we translate from\n",
    "    offset: A 2D offset in NDC coordinates\n",
    "    \"\"\"\n",
    "    if point.ndim == 1:\n",
    "        point = point[None]\n",
    "    # Ask kaolin about the camera up and right axes in world coordinates, and move along them an \"offset\" amount.\n",
    "    # offset is given in \"post projected\" NDC coordinates, so the amount isn't exactly camera-space units.\n",
    "    # However, the important part is we don't move along the camera-forward axis.\n",
    "    fov_x = kal_cam.fov_x\n",
    "    fov_y = kal_cam.fov_y\n",
    "    depth = torch.linalg.norm(point - kal_cam.cam_pos())\n",
    "    offset[0] = offset[0]/1000#*torch.tan(fov_x)\n",
    "    offset[1] = offset[1]/1000#*torch.tan(fov_y)\n",
    "    \n",
    "    translated_point = point.clone()\n",
    "    translated_point += kal_cam.cam_right().squeeze(-1) * offset[0]\n",
    "    translated_point += kal_cam.cam_up().squeeze(-1) * offset[1]\n",
    "    return translated_point\n",
    "    \n",
    "def find_closest_3d_points(query_3d_pts, object_3d_pts, radius, k=10):\n",
    "    \"\"\" Finds points from object_3d_pts to query_3d_pts\n",
    "        Pts should be within radius and limited to a number k\n",
    "    \"\"\"\n",
    "    # Define the radius\n",
    "    r = radius\n",
    "    # Calculate pairwise distances\n",
    "    dists = torch.cdist(query_3d_pts, object_3d_pts)\n",
    "    # Find points within radius r\n",
    "    within_radius = dists <= r\n",
    "    \n",
    "    # Get the indices of object_pts within radius r of any query_pts\n",
    "    indices_within_radius = torch.nonzero(within_radius, as_tuple=True)[1]\n",
    "    if k >= indices_within_radius.shape[0]:\n",
    "        return indices_within_radius, object_3d_pts[indices_within_radius]\n",
    "    else:\n",
    "        # Flatten distances tensor for sorting\n",
    "        dists_flat = dists[within_radius]\n",
    "        # Sort the distances and select top k\n",
    "        sorted_indices = torch.argsort(dists_flat)[:k]\n",
    "        # Select the top k indices\n",
    "        top_k_indices = indices_within_radius[sorted_indices]\n",
    "        # Get the points that are within the radius and in the top k closest\n",
    "        points_within_radius_top_k = object_3d_pts[top_k_indices]\n",
    "        # Get the points that are within the radius\n",
    "        return top_k_indices, points_within_radius_top_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083bce8-a220-42ca-952d-402a3088de94",
   "metadata": {},
   "source": [
    "## Run Interactive Simulation! Use Shift + Click and pull on the object\n",
    "\n",
    "Now, let's enable pulling on object parts during simulation.\n",
    "To interact, simply press \"SHIFT\" and click on the mesh and drag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc3658-f66e-487a-893d-4b1d716f3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_face = -1\n",
    "sim_history = []\n",
    "mesh.vertices = orig_vertices\n",
    "mouse_clicked = 0\n",
    "scene1.sim_obj_dict[obj_idx].reset_sim_state()\n",
    "\n",
    "def boundary_func(pts):\n",
    "    # Extract the z-coordinates (height) of the points\n",
    "    heights = pts[:, 1]\n",
    "    # Determine the minimum and maximum z-coordinates\n",
    "    z_min = torch.min(heights)\n",
    "    z_max = torch.max(heights)\n",
    "    # Calculate the threshold z-coordinate for the upper 10% of the object's height\n",
    "    threshold = z_min + 0.9 * (z_max - z_min)\n",
    "    # Get the indices of the points in the upper 10%\n",
    "    return heights >= threshold\n",
    "\n",
    "boundary1 = scene1.sim_obj_dict[obj_idx].set_boundary_condition(\"boundary1\", boundary_func, bdry_penalty=10000)\n",
    "\n",
    "def additional_event_handler(visualizer, event):\n",
    "    \"\"\"Event handler to be provided to Kaolin's visualizer\"\"\"\n",
    "    global active_face, mesh, mouse_clicked, pull_from_2d, sim_history\n",
    "    \n",
    "    with visualizer.out:\n",
    "        if event['shiftKey']:\n",
    "            #return simplicits_viz_logic(event, visualizer, mouse_clicked, boundary1, pull_from_2d, mesh)\n",
    "            if event['type'] == 'mousedown':\n",
    "                mouse_clicked = 1\n",
    "                pull_from_2d = torch.tensor(visualizer._get_clamped_coords(event), device='cuda', dtype=torch.float)\n",
    "                current_values = visualizer.get_values_under_cursor(event)\n",
    "                active_face = current_values['face_idx'][0][0]\n",
    "                if active_face == -1:\n",
    "                    boundary1.set_pinned_verts(None, None)\n",
    "                    return False\n",
    "        \n",
    "                bdry_inds, bdry_pts = find_closest_3d_points(mesh.vertices[mesh.faces[active_face],:], scene1.get_object_deformed_pts(obj_idx, scene1.sim_obj_dict[obj_idx].sim_pts).squeeze(), radius=0.2, k=10)\n",
    "                \n",
    "                boundary1.set_pinned_verts(bdry_inds, bdry_pts)\n",
    "                visualizer.render_update()\n",
    "                \n",
    "            if event['type'] == 'mousemove':\n",
    "                if mouse_clicked == 1:\n",
    "                    visualizer.out.clear_output()\n",
    "                    pull_to_2d = torch.tensor(visualizer._get_clamped_coords(event), device='cuda', dtype=torch.float)\n",
    "                    pull_to_2d = torch.tensor(visualizer._get_clamped_coords(event), device='cuda', dtype=torch.float)\n",
    "\n",
    "                    # Delta for clicked point\n",
    "                    pxl_offset = (pull_to_2d - pull_from_2d)\n",
    "\n",
    "                    # pxl_offset[0] /= visualizer.width \n",
    "                    # pxl_offset[1] /= visualizer.height\n",
    "\n",
    "                    pinned_verts = boundary1.pinned_vertices\n",
    "                    point = pinned_verts.mean(dim=0) # in 3D world coord\n",
    "                    # Convert to opengl sign convention\n",
    "                    pxl_offset[1] *= -1\n",
    "                    \n",
    "                    # Get updated location of bdry - TODO: (Or Perel) Need to fix this code\n",
    "                    updated_point = convert_offset_to_world_coords(visualizer.camera, point, pxl_offset)\n",
    "                    offset_3d = updated_point - point\n",
    "                    pinned_verts += offset_3d\n",
    "                    boundary1.update_pinned(pinned_verts)\n",
    "                    print(f'point:{point}')\n",
    "                    print(f'updated_pt:{updated_point}')\n",
    "                    print(f'offset:{offset_3d}')\n",
    "                \n",
    "            if event['type'] == 'mouseup':\n",
    "                if mouse_clicked == 1:\n",
    "                    mouse_clicked = 0\n",
    "                    \n",
    "            return False\n",
    "        return True\n",
    "\n",
    "interactive_cam = kal.render.easy_render.default_camera(resolution).cuda()\n",
    "interactive_cam.extrinsics.move_forward(1)\n",
    "interactive_viz = kal.visualize.IpyTurntableVisualizer(\n",
    "    resolution, resolution, copy.deepcopy(interactive_cam), render, fast_render=fast_render,\n",
    "    max_fps=24, world_up_axis=1,\n",
    "    additional_event_handler=additional_event_handler,\n",
    "    additional_watched_events=['mousedown', 'mousemove', 'keydown'] # We need to now watch for key press event\n",
    ")\n",
    "interactive_viz.render_update()\n",
    "\n",
    "global sim_thread_open, sim_thread\n",
    "sim_thread_open = False\n",
    "sim_thread = None\n",
    "\n",
    "def run_sim():\n",
    "    # if shift is pressed, run our logic, else run default logic\n",
    "    for step in range(500):\n",
    "        with interactive_viz.out:\n",
    "            scene1.run_sim_step()\n",
    "            sim_history.append(scene1.get_object_deformed_pts(obj_idx).squeeze())\n",
    "            print('.', end='')\n",
    "        mesh.vertices = sim_history[-1]\n",
    "        interactive_viz.render_update()    \n",
    "\n",
    "# Run sim for num_steps in a different thread\n",
    "# Needed for interactivity\n",
    "def callback(b):\n",
    "    global sim_thread_open, sim_thread\n",
    "    with interactive_viz.out:\n",
    "        if(sim_thread_open):\n",
    "            sim_thread.join()\n",
    "            sim_thread_open = False\n",
    "        sim_thread_open = True\n",
    "        sim_thread = threading.Thread(target=run_sim, daemon=True)\n",
    "        sim_thread.start()\n",
    "        \n",
    "button = Button(description='Run Test')\n",
    "button.on_click(callback)\n",
    "display(HBox([interactive_viz.canvas, button]), interactive_viz.out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
