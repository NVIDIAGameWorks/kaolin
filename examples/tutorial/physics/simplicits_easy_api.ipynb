{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0ce66e-8c08-4c74-a5ae-60592173785d",
   "metadata": {},
   "source": [
    "# Using Simplicit's Easy API To Simulate Avocado Mesh\n",
    "A simple way to use the simplicit's code base. We can create a simple object, train it, simulate it and visualize all in a very few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6dcc14f-a4a3-4c9c-87f8-5a28d6f5a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math, os, sys, logging, threading\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import kaolin as kal\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sys.path.append(str(Path(\"..\")))\n",
    "from tutorial_common import COMMON_DATA_DIR\n",
    "\n",
    "def sample_mesh_path(fname):\n",
    "    return os.path.join(COMMON_DATA_DIR, 'meshes', fname)\n",
    "\n",
    "def print_tensor(t, name='', **kwargs):\n",
    "    print(kal.utils.testing.tensor_info(t, name=name, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492694e2-a66e-43f0-b9b3-4ed36a421e59",
   "metadata": {},
   "source": [
    "## Loading Geometry\n",
    "Simplicies works with any geometry. Meshes, pointclouds, SDFs, Gaussian splats, and more. For this example we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a49d68-c73e-4a06-9708-695e2f201318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot convert Ka from obj mtl to PBR spec; use raw_materials=True to import raw values\n",
      "SurfaceMesh object with batching strategy NONE\n",
      "            vertices: [406, 3] (torch.float32)[cuda:0]  \n",
      "               faces: [682, 3] (torch.int64)[cuda:0]  \n",
      "             normals: [377, 3] (torch.float32)[cuda:0]  \n",
      "    face_normals_idx: [682, 3] (torch.int64)[cuda:0]  \n",
      "                 uvs: [406, 2] (torch.float32)[cuda:0]  \n",
      "        face_uvs_idx: [682, 3] (torch.int64)[cuda:0]  \n",
      "material_assignments: [682] (torch.int16)[cuda:0]  \n",
      "           materials: list of length 1\n",
      "       face_vertices: if possible, computed on access from: (faces, vertices)\n",
      "        face_normals: if possible, computed on access from: (normals, face_normals_idx) or (vertex_normals, faces) or (vertices, faces)\n",
      "            face_uvs: if possible, computed on access from: (uvs, face_uvs_idx)\n",
      "      vertex_normals: if possible, computed on access from: (faces, face_normals)\n",
      "     vertex_tangents: if possible, computed on access from: (faces, face_vertices, face_uvs, vertex_normals)\n",
      "       vertex_colors: if possible, computed on access from: (faces, face_colors)\n",
      "     vertex_features: if possible, computed on access from: (faces, face_features)\n",
      "       face_tangents: if possible, computed on access from: (faces, vertex_tangents)\n",
      "         face_colors: if possible, computed on access from: (faces, vertex_colors)\n",
      "       face_features: if possible, computed on access from: (faces, vertex_features)\n"
     ]
    }
   ],
   "source": [
    "# Import and triangulate to enable rasterization; move to GPU\n",
    "mesh = kal.io.import_mesh(sample_mesh_path('avocado.obj'), triangulate=True).cuda()\n",
    "# Normalize so it is easy to set up default camera\n",
    "mesh.vertices = kal.ops.pointcloud.center_points(mesh.vertices.unsqueeze(0), normalize=True).squeeze(0) \n",
    "orig_vertices = mesh.vertices.clone()  # Also save original undeformed vertices\n",
    "\n",
    "# Inspect\n",
    "print(mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e54cb8-e2d2-4921-814b-62ef9a7b431e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Lets set up the vertices and material parameters of our object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c11c603-4b6f-4229-9303-94c40c8d06b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Physics material parameters\n",
    "soft_youngs_modulus = 1e5\n",
    "poisson_ratio = 0.45\n",
    "rho = 500  # kg/m^3\n",
    "approx_volume = 0.5  # m^3\n",
    "\n",
    "# Points sampled over the object\n",
    "pts = mesh.vertices\n",
    "yms = torch.full((pts.shape[0],), soft_youngs_modulus, device=\"cuda\")\n",
    "prs = torch.full((pts.shape[0],), poisson_ratio, device=\"cuda\")\n",
    "rhos = torch.full((pts.shape[0],), rho, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66146660-e708-4cf7-815c-a1fd5d337053",
   "metadata": {},
   "source": [
    "## Create a SimplicitsObject\n",
    "We make a \"simplicits object\" using our api. Then we train it for num_steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d333391d-618a-4e25-8866-acaec1e3fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 0, le: 428.7832946777344, lo: 32387982.0\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 100, le: 23.801427841186523, lo: 154803.328125\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 200, le: 112.9085464477539, lo: 116969.1796875\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 300, le: 264.17999267578125, lo: 80777.2734375\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 400, le: 308.72802734375, lo: 80147.8515625\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 500, le: 221.305908203125, lo: 80178.9375\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 600, le: 271.9401550292969, lo: 79970.1328125\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 700, le: 165.41661071777344, lo: 77258.0703125\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 800, le: 857.9734497070312, lo: 40415.76953125\n",
      "DEBUG:kaolin.physics.simplicits.easy_api:Training step: 900, le: 632.1121215820312, lo: 42898.03125\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a Simpicits object to enable simulation\n",
    "sim_obj = kal.physics.simplicits.SimplicitsObject(pts, yms, prs, rhos, torch.tensor([approx_volume], dtype=torch.float32, device=\"cuda\"), num_handles=5)\n",
    "sim_obj.train(num_steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0bb9b8-4d0a-43cc-9465-2ea966c515e5",
   "metadata": {},
   "source": [
    "## Create a Scene\n",
    "Now that we're trained the object. Lets simulate it by creating a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad0028-1686-4d4c-a6b5-5e5731ff0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a default scene\n",
    "scene = kal.physics.simplicits.SimplicitsScene() # default empty scene\n",
    "scene.max_newton_steps = 3 #Convergence might not be guaranteed, but runs very fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b0dc8-7673-4297-9403-35334c44443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our object to the scene. The scene copies it into an internal SimulatableObject utility class\n",
    "obj_idx = scene.add_object(sim_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5640e-1008-44d1-a9ae-caa1aad58576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gravity to the scene\n",
    "scene.set_scene_gravity(acc_gravity=torch.tensor([0, 9.8, 0]))\n",
    "# Add floor to the scene\n",
    "scene.set_scene_floor(floor_height=-0.8, floor_axis=1, floor_penalty=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51bb5c-f0ff-4350-aa01-ae244d93f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the object softer by updating the material parameter\n",
    "scene.set_object_materials(0, yms=torch.tensor(5e4, device='cuda', dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed3fec-cc3a-4b0a-b51f-3df7f8333b3c",
   "metadata": {},
   "source": [
    "## Thats it! Onto display\n",
    "All we need to do now is display the object using Kaolin's in-notebook visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30963bf0-06be-4186-b4e0-ab7d377b1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 512\n",
    "camera = kal.render.easy_render.default_camera(resolution).cuda()\n",
    "\n",
    "azimuth = torch.zeros((1,), device='cuda')\n",
    "elevation = torch.full((1,), math.pi / 3., device='cuda')\n",
    "amplitude = torch.full((1, 3), 3., device='cuda')\n",
    "sharpness = torch.full((1,), 5., device='cuda')\n",
    "\n",
    "def current_lighting():\n",
    "    direction = kal.render.lighting.sg_direction_from_azimuth_elevation(azimuth, elevation)\n",
    "    return kal.render.lighting.SgLightingParameters(\n",
    "        amplitude=amplitude, sharpness=sharpness, direction=direction)\n",
    "    \n",
    "def render(in_cam, **kwargs):\n",
    "    active_pass=kal.render.easy_render.RenderPass.render\n",
    "    render_res = kal.render.easy_render.render_mesh(in_cam, mesh, lighting=current_lighting(), **kwargs)\n",
    "    \n",
    "    img = render_res[active_pass]\n",
    "    background_mask = (render_res[kal.render.easy_render.RenderPass.face_idx] < 0).bool()\n",
    "    img2 = torch.clamp(img, 0, 1)[0]\n",
    "    img2[background_mask[0]] = 1\n",
    "    final = (img2 * 255.).to(torch.uint8)\n",
    "    return {\"img\":final, \"face_idx\": render_res[kal.render.easy_render.RenderPass.face_idx].squeeze(0).unsqueeze(-1)}\n",
    "\n",
    "def fast_render(in_cam, factor=8):\n",
    "    lowres_cam = copy.deepcopy(in_cam)\n",
    "    lowres_cam.width = in_cam.width // factor\n",
    "    lowres_cam.height = in_cam.height // factor\n",
    "    return render(lowres_cam)\n",
    "\n",
    "def run_sim():\n",
    "    scene.reset_object(0)\n",
    "\n",
    "    for s in range(100):\n",
    "        with visualizer.out:\n",
    "            scene.run_sim_step()\n",
    "            print(\".\", end=\"\")\n",
    "        mesh.vertices = scene.get_object_deformed_pts(obj_idx).squeeze()\n",
    "        visualizer.render_update()\n",
    "\n",
    "def start_simulation(b):\n",
    "    # run_sim()\n",
    "    t = threading.Thread(target=run_sim, daemon=True)\n",
    "    t.start()\n",
    "\n",
    "scene.reset_object(0)\n",
    "button = Button(description='Run Sim')\n",
    "button.on_click(start_simulation)\n",
    "visualizer = kal.visualize.IpyTurntableVisualizer(\n",
    "    resolution, resolution, copy.deepcopy(camera), render, fast_render=fast_render,\n",
    "    max_fps=24, world_up_axis=1)\n",
    "display(HBox([visualizer.canvas, button]), visualizer.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d30a02-41e1-402d-9fa3-f75b5639c2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
